# Robot_StarForce
2022 개인 프로젝트
<img width="1250" height="938" alt="image" src="https://github.com/user-attachments/assets/752f9490-e86d-40d2-a1b1-726f24dddce8" />

# 제작목적
  4차산업혁명의 핵심기술인 AI시스템의 일종인 시행착오를 거치며 여러단계의 문제해결법을 배우는 강화학습기술을 통한 자율주행 기술을 개발하기 위해서 제작하게 되었습니다. 
강화학습으로 장애물 회피를 학습시키면 직접코딩으로 장애물을 회피하는 것보다 더 유연하고, 피하기 힘든다 상황에서도 회피가 가능할 것이라고 생각했기에 장애물 회피기능에 강화학습을 적용하기로 했습니다. 


# 정보
  Google Deepmind에서 개발한 행동가치 함수(Q-value)를 근사화여 심층신경망을 선택하는 Deep Q Network (DQN)강화학습 알고리즘을 이용해서 Tensorflow2 Keras로 강화학습을 진행하였습니다. 
Lidar 센서를 통해 목적지까지의 거리값, 각도값, 그리고 장애물과의 거리값, 각도값을 4가지 State 대한 로봇의 Action에 따라서  Reward값을 정해줬습니다.
ROS2 foxy버전의 Gazebo환경에서 Trutlebot3 코드를 참고하여 강화학습 코드를 작성하였고, 장애물회피 자율주행을 학습하였습니다. 이를 통해 원하는 목적지까지 따로 제어코드 없이 강화학습 코드만을 통해 장애물을 회피하면서 자율주행이 가능합니다. 

# 구조도
<img width="859" height="299" alt="image" src="https://github.com/user-attachments/assets/77e5c651-0907-4d3d-b09c-d94623684ccf" />

<img width="1840" height="970" alt="image" src="https://github.com/user-attachments/assets/3216c7ca-88b3-4de6-b3e4-8dc096fb8375" />

# 결과 
 ROS2 및 강화학습에 대한 전반적인 이해도를 높일 수 있는 경험이었습니다. 짧은 기간과 처음 해보는 딥러닝에 대한 지식 부족 및 로봇 구조에 대한 한계 때문에 높은 성공률로 학습시키지는 못했지만 딥러닝에 대한 학습 및 로봇 구조 변경 후 다시 한 번 시도한다면 정확도를 높일 수 있을 것으로 보입니다. Gazebo를 사용한 시뮬레이션 환경 구성과 시뮬레이션을 통한 학습 방법에 대해 배울 수 있었고, 여러가지 조건을 부여함에 따라 강화학습 성공률을 높일 수 있었고, 다양한 경우의 수가 존재함을 알 수 있었습니다. 로봇제작 및 설계에 대한 능력 향상 및 시뮬레이션 환경과 실제환경에서 고려해야할 사항들에 대해서도 생각해볼 수 있는 기회였습니다. 강화학습을 자율주행에 적용한다면 사람의 계산만으로 예측할 수 없는 부분까지도 대처가 가능해질 수 있을 것으로 보입니다. 
